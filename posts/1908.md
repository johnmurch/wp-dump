---
title: "Customize Robots.txt Rules For The Botify Crawler"
date: 2014-04-28T00:00:00
excerpt: "<p>Customize Robots.txt Rules for the Botify Crawler 28th April 2014Annabelle A much anticipated feature is now available: the ability to customize robots.txt rules for the Botify crawler. It&#8217;s called Virtual Robots.txt. Simply enter the new rules in Botify&#8217;s crawl setup interface, and this Virtual Robots.txt will override the robots.txt from your website. Virtual Robots.txt, what&hellip; </p>
<p><a class=\"moretag\" href=\"https://www.botify.com/blog/virtual-robots-txt\">Read the full article</a></p>"
slug: virtual-robots-txt
---

<header class="text-center">
<h1 class="font-internacional font-regular normal text-header-one leading-header-one text-typography-accent-2">Customize Robots.txt Rules for the Botify Crawler</h1>
<div class="flex items-center justify-center my-3"><span class="mr-1 font-internacional font-regular normal text-base leading-none text-typography-primary-lighter">28th April 2014</span><img decoding="async" alt="Annabelle" class="rounded-full w-10 h-10" src="//images.ctfassets.net/tp56mevc46jo/2fCkDEsbiQSWGIkcWs40mG/e548033eda97a957ca690bdc814ed048/HS-PNG-100x100-Annabelle_Bouard.png"><span class="ml-1 font-internacional font-regular normal text-base leading-none text-typography-primary">Annabelle</span></div>
</header>
<p><span class="font-roboto font-regular normal text-base leading-none Markdown__Container"></span></p>
<p>A much anticipated feature is now available: the ability to customize robots.txt rules for the Botify crawler.</p>
<p>It&#8217;s called Virtual Robots.txt. Simply enter the new rules in Botify&#8217;s crawl setup interface, and this Virtual Robots.txt will override the robots.txt  from your website.</p>
<p><strong>Virtual Robots.txt, what for?</strong></p>
<p>The Botify crawler&#8217;s default behavior is to follow the rules defined for Google in your website&#8217;s robots.txt file, alternatively those defined for any robot.</p>
<p>What if you only want to crawl a subset  of the URLs currently allowed to robots? You may want to leave out some content that is not central to your website analysis but might take a serious toll on crawl time (such as forums or user comments).</p>
<p>What if, on the contrary, you want to crawl URLs that are currently disallowed to robots? For instance,  a brand new version of your website only available in a staging environment.</p>
<p>Anything becomes possible with the Virtual Robots.txt.</p>
<p><strong>How it works</strong></p>
<p>It&#8217;s extremely simple. You will find a &#8220;Add Virtual Robotx.txt&#8221; button at the bottom of the Botify crawl setup page:</p>
<p><img decoding="async" alt="Botify crawl setup Virtual Robots.txt screenshot" src="https://gm01botify.wpengine.com/wp-content/uploads/2020/01/20140429_081618_virtual-robots-txt.png" title="Botify crawl setup page"></p>
<p>The easiest &#8211; and safest &#8211; way to go is to copy and paste the existing robots.txt file from your website, and apply your changes. The Botify crawler supports the standard robots.txt syntax, as well as Google&#8217;s most common extensions (such as a mid-string wildcard, for instance &#8220;Disallow: /resources/*/data/&#8221;).</p>
<p>The Botify crawler will follow the directives for the Botify user-agent, or those for the Googlebot user-agent, or those for any (*) user-agent : it selects one set of rules only, the first available in that order. This provides flexibility when setting up the Virtual Robots.txt : you can update the Googlebot section, or create a new section for Botify.</p>
<p><strong>In the case of multi-domain crawls</strong></p>
<p>What if you are crawling subdomains (*.mywebsite.com) or multiple domains (<a href="http://www.mywebsite.com">www.mywebsite.com</a>, <a href="http://www.mywebsite.co.uk">www.mywebsite.co.uk</a>, <a href="http://www.mywebsite.de">www.mywebsite.de</a>, etc.)? There could be as many distinct robots.txt files. Well, no problem, the Virtual Robots.txt can combine several regular robots.txt files. All you need to do is add a specific header which indicates what protocol and domain a robots.txt content applies to, and add those one after the other:</p>
<pre><code>[header]   # ex: [http://www.webmysite.com], for the website's main domain
regular robots.txt content

[header]   # ex: [http://*.webmysite.com], for all other sub-domains
regular robots.txt content

[header]   # ex: |https://*], for all https pages
regular robots.txt content

etc.</code></pre>
<p>For header syntax and options, please refer to the <a href="https://www.botify.com/support/virtual-robotstxt-option/">Virtual Robots.txt FAQ</a>.</p>
<p>No header is needed for ONE robots.txt content. The robots.txt rules will then apply to ALL crawled domains.</p>
<p><strong>Only cover the domains you want to change</strong></p>
<p>As mentionned at the beginning of this post, the Virtual Robots.txt supersedes robots.txt files. This means that if the Virtual Robots.txt includes rules for a given domain (more specifically, for protocol + domain), then the robots.txt from the website will be ignored as a whole.  However, the Botify crawler will still use the online robots.txt file for domains not covered in the Virtual Robots.txt.</p>
<p>Got any question? Check out the <a href="https://www.botify.com/support/virtual-robotstxt-option/">Virtual Robots.txt FAQ</a>.</p>
<p>While we&#8217;re covering robots.txt options for the Botify crawler:</p>
<p>There is an alternative to a Virtual Robots.txt : simply add a set of rules for Botify (user-agent: botify) to your website&#8217;s robots.txt file. However, for some of you, updating the robots.txt is not as straightforward as it seems, you may not have easy access to the file, it may involve a 3rd party, etc. It will most probably be more time consuming than using the Virtual Robots.txt, especially when the crawl covers several domains. Either way, it&#8217;s up to you!</p>
<div class="tags leading-big border-t border-b border-brand-quaternary-lighter mt-4"><span class="mr-1 font-roboto font-regular normal text-base leading-none">Category:</span><span><a class="uppercase text-typography-accent-1" href="/platform">Product Features</a></span></div>
<footer class="flex justify-center my-5 mx-5">
<div class="mr-1 w-1/2 text-right">
<p><span class="font-internacional font-regular normal text-base leading-none text-typography-primary">Previous Article</span></p>
<p><a class="inline-block mt-2" href="/blog/segmentation"><span class="font-roboto font-regular normal text-base leading-none text-typography-accent-4">No Meaningful SEO Analysis Without Segmentation</span></a></p>
</div>
<div class="ml-1 w-1/2">
<p><span class="font-internacional font-regular normal text-base leading-none text-typography-primary">Next Article</span></p>
<p><a class="inline-block mt-2" href="/blog/suggested-patterns-simon"><span class="font-roboto font-regular normal text-base leading-none text-typography-accent-4">Simon Explains Suggested Patterns</span></a></p>
</div>
</footer>
<div shortname="botify" title="Customize Robots.txt Rules for the Botify Crawler" url="https://www.botify.com/blog/virtual-robots-txt">
<div id="disqus_thread_old"></div>
<p><a class="dsq-brlink" href="http://disqus.com">Blog comments powered by <span class="logo-disqus">Disqus</span>.</a></p>
</div>
